{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import csv\n",
    "import numpy as np\n",
    "\n",
    "filename = \"data-raw/Tom LD _ Life Story Presentation.txt\"\n",
    "\n",
    "    # Specify model path\n",
    "model_path = \"GloVE/glove.6B/glove.6B.300d.txt\"\n",
    "\n",
    "words = pd.read_table(\n",
    "    model_path, sep=\" \", index_col=0, header=None, quoting=csv.QUOTE_NONE\n",
    ")\n",
    "\n",
    "model_df = pd.read_table(model_path, sep=\" \", index_col=0, header=None, quoting=3)\n",
    "model_dict = {\n",
    "    word: embeddings for word, embeddings in zip(model_df.index, model_df.values)\n",
    "}\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "from functions.embeddings_using_pd import get_word_embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(14, 300)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "em = get_word_embeddings(filename, model_path)\n",
    "em.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_content(filename):\n",
    "       # Open the input file and read its contents\n",
    "    with open(filename, \"r\") as f:\n",
    "        contents = f.read()\n",
    "\n",
    "    # Split the contents into blocks based on integer line followed by a blank line\n",
    "    blocks = contents.split(\"\\n\\n\")\n",
    "\n",
    "    return blocks\n",
    "\n",
    "blocks = get_content(filename)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'We are all just chemical reactions on a small rock flying through incomprehensible space\\n'"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "blocks[66]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Iterate over the blocks and extract the word embeddings for each one\n",
    "embeddings_list = []\n",
    "for block in blocks:\n",
    "    # Tokenize the block into individual words\n",
    "    words = block.split()\n",
    "    # Create an empty array to store the embeddings for each word\n",
    "    embeddings = np.zeros((len(words), len(model_dict[next(iter(model_dict))])))\n",
    "    # Iterate over the words and get their embeddings\n",
    "    for i, word in enumerate(words):\n",
    "        if word in model_dict:\n",
    "            embeddings[i] = model_dict[word]\n",
    "\n",
    "    # Calculate the mean embedding for the block\n",
    "    mean_embedding = np.mean(embeddings, axis=0)\n",
    "    embeddings_list.append(mean_embedding)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(67, 300)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array(embeddings_list).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def main():\n",
    "#     # Specify file path\n",
    "#     filename = \"data-raw/Tom LD _ Life Story Presentation.txt\"\n",
    "\n",
    "#     # Specify model path\n",
    "#     model_path = \"GloVE/glove.6B/glove.6B.300d.txt\"\n",
    "\n",
    "#     embeddings_list = get_word_embeddings(filename, model_path)\n",
    "\n",
    "#     print(embeddings_list.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.manifold import TSNE\n",
    "import graphviz as gv\n",
    "from PIL import Image\n",
    "\n",
    "\n",
    "def reduce_and_draw_network_map_with_images(\n",
    "    embeddings, image_folder, handle_isolates=True\n",
    "):\n",
    "    # Perform t-SNE to reduce the embeddings to 2 dimensions\n",
    "    tsne = TSNE(n_components=2, random_state=42, perplexity=5)\n",
    "    embeddings_2d = tsne.fit_transform(embeddings)\n",
    "\n",
    "    # Find isolated nodes if requested\n",
    "    if handle_isolates:\n",
    "        degrees = np.sum(np.abs(np.sign(np.dot(embeddings, embeddings.T))), axis=1)\n",
    "        isolated_nodes = np.where(degrees == 0)[0]\n",
    "    else:\n",
    "        isolated_nodes = []\n",
    "\n",
    "    # Create a Graphviz graph object\n",
    "    graph = gv.Graph(engine=\"neato\")\n",
    "\n",
    "    # Add nodes to the graph\n",
    "    for i in range(len(embeddings_2d)):\n",
    "        # Load image\n",
    "        img_path = f\"{image_folder}/Slide{i+1}.jpeg\"\n",
    "        # img = Image.open(img_path)  # .resize((50, 50))\n",
    "\n",
    "        # Add node with image\n",
    "        with graph.subgraph(name=f\"cluster_{i}\") as c:\n",
    "            c.attr(label=f\"{i}\")\n",
    "            c.attr(fontsize=\"10\")\n",
    "            c.attr(style=\"filled\")\n",
    "            c.attr(color=\"black\")\n",
    "            c.node(f\"node{i}\", image=img_path, shape=\"none\", label=\"\")\n",
    "\n",
    "            # Set position of cluster\n",
    "            if i in isolated_nodes:\n",
    "                c.attr(pos=f\"{2*embeddings_2d[i,0]},{2*embeddings_2d[i,1]}!\")\n",
    "            else:\n",
    "                c.attr(pos=f\"{embeddings_2d[i,0]},{embeddings_2d[i,1]}!\")\n",
    "\n",
    "    # Add edges to the graph\n",
    "    for i in range(len(embeddings_2d)):\n",
    "        for j in range(i + 1, len(embeddings_2d)):\n",
    "            similarity = np.dot(embeddings[i], embeddings[j]) / (\n",
    "                np.linalg.norm(embeddings[i]) * np.linalg.norm(embeddings[j])\n",
    "            )\n",
    "            if similarity > 0.8:\n",
    "                graph.edge(f\"node{i}\", f\"node{j}\", weight=str(similarity))\n",
    "\n",
    "    # Draw the network map\n",
    "    graph.format = \"pdf\"\n",
    "    graph.render(filename=\"network_map_with_images 6\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/zellaking/.pyenv/versions/3.9.9/envs/keras/lib/python3.9/site-packages/sklearn/manifold/_t_sne.py:800: FutureWarning: The default initialization in TSNE will change from 'random' to 'pca' in 1.2.\n",
      "  warnings.warn(\n",
      "/Users/zellaking/.pyenv/versions/3.9.9/envs/keras/lib/python3.9/site-packages/sklearn/manifold/_t_sne.py:810: FutureWarning: The default learning rate in TSNE will change from 200.0 to 'auto' in 1.2.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "reduce_and_draw_network_map_with_images(np.array(embeddings_list[1:]), 'img', handle_isolates=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "keras",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
